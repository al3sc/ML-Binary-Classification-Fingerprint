{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Models I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn.datasets \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.linalg\n",
    "import scipy.special\n",
    "\n",
    "import project_module as pm\n",
    "\n",
    "inputFile = './input/trainData.txt'\n",
    "\n",
    "# restart kernel\n",
    "import importlib\n",
    "importlib.reload(pm)\n",
    "\n",
    "D, L = pm.load(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default font size - comment to use default values\n",
    "plt.rc('font', size=16)\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DTR, LTR), (DVAL, LVAL) = pm.split_db_2to1(D, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a dictionary of ML parameters for each class\n",
    "def Gau_MVG_ML_estimates(D, L):\n",
    "    labelSet = set(L)\n",
    "    hParams = {}\n",
    "    for lab in labelSet:\n",
    "        DX = D[:, L==lab]\n",
    "        hParams[lab] = pm.compute_mu_C(DX)\n",
    "    return hParams\n",
    "\n",
    "# Compute a dictionary of ML parameters for each class - Naive Bayes version of the model\n",
    "# We compute the full covariance matrix and then extract the diagonal. Efficient implementations would work directly with just the vector of variances (diagonal of the covariance matrix)\n",
    "def Gau_Naive_ML_estimates(D, L):\n",
    "    labelSet = set(L)\n",
    "    hParams = {}\n",
    "    for lab in labelSet:\n",
    "        DX = D[:, L==lab]\n",
    "        mu, C = pm.compute_mu_C(DX)\n",
    "        hParams[lab] = (mu, C * numpy.eye(D.shape[0]))          # multiply by the identity matrix -> diagonal covariance matrix \n",
    "    return hParams\n",
    "\n",
    "# Compute a dictionary of ML parameters for each class - Tied Gaussian model\n",
    "# We exploit the fact that the within-class covariance matrix is a weighted mean of the covraince matrices of the different classes\n",
    "def Gau_Tied_ML_estimates(D, L):\n",
    "    labelSet = set(L)\n",
    "    hParams = {}\n",
    "    hMeans = {}\n",
    "    CGlobal = 0\n",
    "    for lab in labelSet:\n",
    "        DX = D[:, L==lab]\n",
    "        mu, C_class = pm.compute_mu_C(DX)\n",
    "        CGlobal += C_class * DX.shape[1]\n",
    "        hMeans[lab] = mu\n",
    "    CGlobal = CGlobal / D.shape[1]\n",
    "    for lab in labelSet:\n",
    "        hParams[lab] = (hMeans[lab], CGlobal)\n",
    "    return hParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-class log-densities. We assume classes are labeled from 0 to C-1. The parameters of each class are in hParams (for class i, hParams[i] -> (mean, cov))\n",
    "def compute_log_likelihood_Gau(D, hParams):\n",
    "\n",
    "    S = numpy.zeros((len(hParams), D.shape[1]))\n",
    "    for lab in range(S.shape[0]):\n",
    "        S[lab, :] = pm.logpdf_GAU_ND(D, hParams[lab][0], hParams[lab][1])           # for each sample of the class lab, the value associated to the log-density\n",
    "    return S\n",
    "\n",
    "# compute log-postorior matrix from log-likelihood matrix and prior array\n",
    "def compute_logPosterior(S_logLikelihood, v_prior):\n",
    "    logSJoint = S_logLikelihood + pm.vcol(numpy.log(v_prior))                   # joint log-density \n",
    "    logSMarginal = pm.vrow(scipy.special.logsumexp(logSJoint, axis=0))          # marginal log-density\n",
    "    logSPost = logSJoint - logSMarginal                                         # log-posteriors\n",
    "    return logSPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryMVGModels(name, DTR, LTR, DVAL, LVAL, ML_func=Gau_MVG_ML_estimates, prior1=1/2):\n",
    "  hParams = ML_func(DTR, LTR)\n",
    "\n",
    "  S_logLikelihood = compute_log_likelihood_Gau(DVAL, hParams)\n",
    "\n",
    "  llr = S_logLikelihood[1] - S_logLikelihood[0]\n",
    "  threshold = -numpy.log( prior1 / (1 - prior1) )     # 0\n",
    "\n",
    "  predictions_class1 = numpy.array(llr >= threshold)\n",
    "\n",
    "  n_correct_predictions = numpy.sum(predictions_class1 == LVAL)\n",
    "  n_wrong_predictions = numpy.sum(predictions_class1 != LVAL)\n",
    "\n",
    "  print(f'Model: {name}')\n",
    "\n",
    "  print(f'Total number of samples: {DVAL.shape[1]}')\n",
    "  print(f'Number of correct predictions: {n_correct_predictions}')\n",
    "  print(f'Number of wrong predictions: {n_wrong_predictions}')\n",
    "\n",
    "  accuracy = n_correct_predictions/DVAL.shape[1]\n",
    "  error_rate = n_wrong_predictions/DVAL.shape[1]\n",
    "\n",
    "  print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "  print(f'Error rate: {error_rate*100:.2f}%')\n",
    "\n",
    "  print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1860\n",
      "Number of wrong predictions: 140\n",
      "Accuracy: 93.00%\n",
      "Error rate: 7.00%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1814\n",
      "Number of wrong predictions: 186\n",
      "Accuracy: 90.70%\n",
      "Error rate: 9.30%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1856\n",
      "Number of wrong predictions: 144\n",
      "Accuracy: 92.80%\n",
      "Error rate: 7.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MVG\n",
    "binaryMVGModels(\"MVG\", DTR, LTR, DVAL, LVAL)\n",
    "\n",
    "# MVG Tied\n",
    "binaryMVGModels(\"Tied MVG\", DTR, LTR, DVAL, LVAL, ML_func=Gau_Tied_ML_estimates)\n",
    "\n",
    "# MVG Naive Bayes\n",
    "binaryMVGModels(\"Naive Bayes MVG\", DTR, LTR, DVAL, LVAL, ML_func=Gau_Naive_ML_estimates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVG results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MVG results analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"MVG results analysis\")\n",
    "hParams_MVG = Gau_MVG_ML_estimates(DTR, LTR)\n",
    "\n",
    "Cs = [ hParams_MVG[0][1], hParams_MVG[1][1] ]\n",
    "classes = ['Fake', 'Genuine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Fake\n",
      "Feature 1 variance: 0.6009565063742803.\n",
      "   Covariance with feature 2: 5.158665171145649e-05 \t(Variance - Covariance: 0.601)\n",
      "   Covariance with feature 3: 0.01905891448976418 \t(Variance - Covariance: 0.582)\n",
      "   Covariance with feature 4: 0.019252987552578038 \t(Variance - Covariance: 0.582)\n",
      "   Covariance with feature 5: 0.012803940239193384 \t(Variance - Covariance: 0.588)\n",
      "   Covariance with feature 6: -0.013472159793695327 \t(Variance - Covariance: 0.614)\n",
      "Feature 2 variance: 1.4472254272925504.\n",
      "   Covariance with feature 1: 5.158665171145649e-05 \t(Variance - Covariance: 1.447)\n",
      "   Covariance with feature 3: -0.016134010951526962 \t(Variance - Covariance: 1.463)\n",
      "   Covariance with feature 4: -0.015856147392157894 \t(Variance - Covariance: 1.463)\n",
      "   Covariance with feature 5: -0.026452914117622562 \t(Variance - Covariance: 1.474)\n",
      "   Covariance with feature 6: 0.022913983275498137 \t(Variance - Covariance: 1.424)\n",
      "Feature 3 variance: 0.5653489011392431.\n",
      "   Covariance with feature 1: 0.01905891448976418 \t(Variance - Covariance: 0.546)\n",
      "   Covariance with feature 2: -0.016134010951526962 \t(Variance - Covariance: 0.581)\n",
      "   Covariance with feature 4: -0.0018434443520603252 \t(Variance - Covariance: 0.567)\n",
      "   Covariance with feature 5: -0.006914462774895378 \t(Variance - Covariance: 0.572)\n",
      "   Covariance with feature 6: 0.016892832159975633 \t(Variance - Covariance: 0.548)\n",
      "Feature 4 variance: 0.5416152015143372.\n",
      "   Covariance with feature 1: 0.019252987552578038 \t(Variance - Covariance: 0.522)\n",
      "   Covariance with feature 2: -0.015856147392157894 \t(Variance - Covariance: 0.557)\n",
      "   Covariance with feature 3: -0.0018434443520603252 \t(Variance - Covariance: 0.543)\n",
      "   Covariance with feature 5: 0.005251713747748153 \t(Variance - Covariance: 0.536)\n",
      "   Covariance with feature 6: 0.013571777454355508 \t(Variance - Covariance: 0.528)\n",
      "Feature 5 variance: 0.6960676413130412.\n",
      "   Covariance with feature 1: 0.012803940239193384 \t(Variance - Covariance: 0.683)\n",
      "   Covariance with feature 2: -0.026452914117622562 \t(Variance - Covariance: 0.723)\n",
      "   Covariance with feature 3: -0.006914462774895378 \t(Variance - Covariance: 0.703)\n",
      "   Covariance with feature 4: 0.005251713747748153 \t(Variance - Covariance: 0.691)\n",
      "   Covariance with feature 6: 0.01584383987307943 \t(Variance - Covariance: 0.680)\n",
      "Feature 6 variance: 0.6865197101792836.\n",
      "   Covariance with feature 1: -0.013472159793695327 \t(Variance - Covariance: 0.700)\n",
      "   Covariance with feature 2: 0.022913983275498137 \t(Variance - Covariance: 0.664)\n",
      "   Covariance with feature 3: 0.016892832159975633 \t(Variance - Covariance: 0.670)\n",
      "   Covariance with feature 4: 0.013571777454355508 \t(Variance - Covariance: 0.673)\n",
      "   Covariance with feature 5: 0.01584383987307943 \t(Variance - Covariance: 0.671)\n",
      "\n",
      "Class Genuine\n",
      "Feature 1 variance: 1.4480952651315968.\n",
      "   Covariance with feature 2: -0.014722243328396983 \t(Variance - Covariance: 1.463)\n",
      "   Covariance with feature 3: 0.005570103005566303 \t(Variance - Covariance: 1.443)\n",
      "   Covariance with feature 4: 0.01574158827246969 \t(Variance - Covariance: 1.432)\n",
      "   Covariance with feature 5: 0.019497116307738226 \t(Variance - Covariance: 1.429)\n",
      "   Covariance with feature 6: -0.00017668253949570457 \t(Variance - Covariance: 1.448)\n",
      "Feature 2 variance: 0.5533907963148345.\n",
      "   Covariance with feature 1: -0.014722243328396983 \t(Variance - Covariance: 0.568)\n",
      "   Covariance with feature 3: -0.011216868067157425 \t(Variance - Covariance: 0.565)\n",
      "   Covariance with feature 4: -0.009064733593833429 \t(Variance - Covariance: 0.562)\n",
      "   Covariance with feature 5: -0.014658990069187318 \t(Variance - Covariance: 0.568)\n",
      "   Covariance with feature 6: 0.016349204829718463 \t(Variance - Covariance: 0.537)\n",
      "Feature 3 variance: 0.5574802287006138.\n",
      "   Covariance with feature 1: 0.005570103005566303 \t(Variance - Covariance: 0.552)\n",
      "   Covariance with feature 2: -0.011216868067157425 \t(Variance - Covariance: 0.569)\n",
      "   Covariance with feature 4: 0.027560966325901916 \t(Variance - Covariance: 0.530)\n",
      "   Covariance with feature 5: -0.003769664507982207 \t(Variance - Covariance: 0.561)\n",
      "   Covariance with feature 6: -0.0145976943367627 \t(Variance - Covariance: 0.572)\n",
      "Feature 4 variance: 0.5696570132972495.\n",
      "   Covariance with feature 1: 0.01574158827246969 \t(Variance - Covariance: 0.554)\n",
      "   Covariance with feature 2: -0.009064733593833429 \t(Variance - Covariance: 0.579)\n",
      "   Covariance with feature 3: 0.027560966325901916 \t(Variance - Covariance: 0.542)\n",
      "   Covariance with feature 5: -0.011698340398559154 \t(Variance - Covariance: 0.581)\n",
      "   Covariance with feature 6: 0.034993186259353874 \t(Variance - Covariance: 0.535)\n",
      "Feature 5 variance: 1.342017674767238.\n",
      "   Covariance with feature 1: 0.019497116307738226 \t(Variance - Covariance: 1.323)\n",
      "   Covariance with feature 2: -0.014658990069187318 \t(Variance - Covariance: 1.357)\n",
      "   Covariance with feature 3: -0.003769664507982207 \t(Variance - Covariance: 1.346)\n",
      "   Covariance with feature 4: -0.011698340398559154 \t(Variance - Covariance: 1.354)\n",
      "   Covariance with feature 6: 0.016945409576266415 \t(Variance - Covariance: 1.325)\n",
      "Feature 6 variance: 1.3037188044712757.\n",
      "   Covariance with feature 1: -0.00017668253949570457 \t(Variance - Covariance: 1.304)\n",
      "   Covariance with feature 2: 0.016349204829718463 \t(Variance - Covariance: 1.287)\n",
      "   Covariance with feature 3: -0.0145976943367627 \t(Variance - Covariance: 1.318)\n",
      "   Covariance with feature 4: 0.034993186259353874 \t(Variance - Covariance: 1.269)\n",
      "   Covariance with feature 5: 0.016945409576266415 \t(Variance - Covariance: 1.287)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(classes):\n",
    "  print(f'Class {label}')\n",
    "  C = Cs[i]\n",
    "  for dIdx1 in range(C.shape[0]):\n",
    "    feat_covariances = []\n",
    "    variance = C[dIdx1][dIdx1]\n",
    "\n",
    "    for dIdx2 in range(C.shape[1]):\n",
    "      if(dIdx1 != dIdx2):\n",
    "        covariance = C[dIdx1][dIdx2]\n",
    "        feat_covariances.append( (dIdx2+1, covariance, (variance - covariance)) )\n",
    "    \n",
    "    print(f'Feature {dIdx1+1} variance: {variance}.')\n",
    "    for cov_info in feat_covariances:\n",
    "      print(f'   Covariance with feature {cov_info[0]}: {cov_info[1]} \\t(Variance - Covariance: {cov_info[2]:.3f})')\n",
    "  \n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Fake\n",
      "[[ 1.    0.    0.03  0.03  0.02 -0.02]\n",
      " [ 0.    1.   -0.02 -0.02 -0.03  0.02]\n",
      " [ 0.03 -0.02  1.   -0.   -0.01  0.03]\n",
      " [ 0.03 -0.02 -0.    1.    0.01  0.02]\n",
      " [ 0.02 -0.03 -0.01  0.01  1.    0.02]\n",
      " [-0.02  0.02  0.03  0.02  0.02  1.  ]]\n",
      "Class Genuine\n",
      "[[ 1.   -0.02  0.01  0.02  0.01 -0.  ]\n",
      " [-0.02  1.   -0.02 -0.02 -0.02  0.02]\n",
      " [ 0.01 -0.02  1.    0.05 -0.   -0.02]\n",
      " [ 0.02 -0.02  0.05  1.   -0.01  0.04]\n",
      " [ 0.01 -0.02 -0.   -0.01  1.    0.01]\n",
      " [-0.    0.02 -0.02  0.04  0.01  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(classes):\n",
    "  print(f'Class {label}')\n",
    "  C = Cs[i]\n",
    "  Corr = C / ( pm.vcol(C.diagonal()**0.5) * pm.vrow(C.diagonal()**0.5) )\n",
    "  Corr_rounded = numpy.round(Corr, 2)\n",
    "  print(Corr_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVG - No feature 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Model: MVG - First 4 features\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1841\n",
      "Number of wrong predictions: 159\n",
      "Accuracy: 92.05%\n",
      "Error rate: 7.95%\n",
      "\n",
      "Model: Tied MVG - First 4 features\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1810\n",
      "Number of wrong predictions: 190\n",
      "Accuracy: 90.50%\n",
      "Error rate: 9.50%\n",
      "\n",
      "Model: Naive Bayes MVG - First 4 features\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1847\n",
      "Number of wrong predictions: 153\n",
      "Accuracy: 92.35%\n",
      "Error rate: 7.65%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "truncatedDTR = DTR[:4]\n",
    "truncatedDVAL = DVAL[:4]\n",
    "print(truncatedDTR.shape[0])\n",
    "binaryMVGModels(\"MVG - First 4 features\", truncatedDTR, LTR, truncatedDVAL, LVAL)\n",
    "binaryMVGModels(\"Tied MVG - First 4 features\", truncatedDTR, LTR, truncatedDVAL, LVAL, ML_func=Gau_Tied_ML_estimates)\n",
    "binaryMVGModels(\"Naive Bayes MVG - First 4 features\", truncatedDTR, LTR, truncatedDVAL, LVAL, ML_func=Gau_Naive_ML_estimates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVG vs Tied MVG - Features 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MVG - Features 1-2\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1270\n",
      "Number of wrong predictions: 730\n",
      "Accuracy: 63.50%\n",
      "Error rate: 36.50%\n",
      "\n",
      "Model: Tied MVG - Features 1-2\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1011\n",
      "Number of wrong predictions: 989\n",
      "Accuracy: 50.55%\n",
      "Error rate: 49.45%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaryMVGModels(\"MVG - Features 1-2\", DTR[:2], LTR, DVAL[:2], LVAL)\n",
    "binaryMVGModels(\"Tied MVG - Features 1-2\", DTR[:2], LTR, DVAL[:2], LVAL, ML_func=Gau_Tied_ML_estimates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MVG - Features 3-4\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1811\n",
      "Number of wrong predictions: 189\n",
      "Accuracy: 90.55%\n",
      "Error rate: 9.45%\n",
      "\n",
      "Model: Tied MVG - Features 3-4\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1812\n",
      "Number of wrong predictions: 188\n",
      "Accuracy: 90.60%\n",
      "Error rate: 9.40%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaryMVGModels(\"MVG - Features 3-4\", DTR[2:4], LTR, DVAL[2:4], LVAL)\n",
    "binaryMVGModels(\"Tied MVG - Features 3-4\", DTR[2:4], LTR, DVAL[2:4], LVAL, ML_func=Gau_Tied_ML_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA as pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA pre-processing - 1 directions\n",
      "\n",
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1815\n",
      "Number of wrong predictions: 185\n",
      "Accuracy: 90.75%\n",
      "Error rate: 9.25%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1813\n",
      "Number of wrong predictions: 187\n",
      "Accuracy: 90.65%\n",
      "Error rate: 9.35%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1815\n",
      "Number of wrong predictions: 185\n",
      "Accuracy: 90.75%\n",
      "Error rate: 9.25%\n",
      "\n",
      "\n",
      "PCA pre-processing - 2 directions\n",
      "\n",
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1824\n",
      "Number of wrong predictions: 176\n",
      "Accuracy: 91.20%\n",
      "Error rate: 8.80%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1815\n",
      "Number of wrong predictions: 185\n",
      "Accuracy: 90.75%\n",
      "Error rate: 9.25%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1823\n",
      "Number of wrong predictions: 177\n",
      "Accuracy: 91.15%\n",
      "Error rate: 8.85%\n",
      "\n",
      "\n",
      "PCA pre-processing - 3 directions\n",
      "\n",
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1824\n",
      "Number of wrong predictions: 176\n",
      "Accuracy: 91.20%\n",
      "Error rate: 8.80%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1815\n",
      "Number of wrong predictions: 185\n",
      "Accuracy: 90.75%\n",
      "Error rate: 9.25%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1820\n",
      "Number of wrong predictions: 180\n",
      "Accuracy: 91.00%\n",
      "Error rate: 9.00%\n",
      "\n",
      "\n",
      "PCA pre-processing - 4 directions\n",
      "\n",
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1839\n",
      "Number of wrong predictions: 161\n",
      "Accuracy: 91.95%\n",
      "Error rate: 8.05%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1815\n",
      "Number of wrong predictions: 185\n",
      "Accuracy: 90.75%\n",
      "Error rate: 9.25%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1823\n",
      "Number of wrong predictions: 177\n",
      "Accuracy: 91.15%\n",
      "Error rate: 8.85%\n",
      "\n",
      "\n",
      "PCA pre-processing - 5 directions\n",
      "\n",
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1858\n",
      "Number of wrong predictions: 142\n",
      "Accuracy: 92.90%\n",
      "Error rate: 7.10%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1814\n",
      "Number of wrong predictions: 186\n",
      "Accuracy: 90.70%\n",
      "Error rate: 9.30%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1825\n",
      "Number of wrong predictions: 175\n",
      "Accuracy: 91.25%\n",
      "Error rate: 8.75%\n",
      "\n",
      "\n",
      "PCA pre-processing - 6 directions\n",
      "\n",
      "Model: MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1860\n",
      "Number of wrong predictions: 140\n",
      "Accuracy: 93.00%\n",
      "Error rate: 7.00%\n",
      "\n",
      "Model: Tied MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1814\n",
      "Number of wrong predictions: 186\n",
      "Accuracy: 90.70%\n",
      "Error rate: 9.30%\n",
      "\n",
      "Model: Naive Bayes MVG\n",
      "Total number of samples: 2000\n",
      "Number of correct predictions: 1822\n",
      "Number of wrong predictions: 178\n",
      "Accuracy: 91.10%\n",
      "Error rate: 8.90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(6):\n",
    "  print()\n",
    "  print(f'PCA pre-processing - {m+1} directions\\n')\n",
    "  UPCA = pm.compute_pca(DTR, m+1)     # trained model\n",
    "  DTR_pca = pm.apply_pca(UPCA, DTR)\n",
    "  DVAL_pca = pm.apply_pca(UPCA, DVAL)\n",
    "\n",
    "  binaryMVGModels(\"MVG\", DTR_pca, LTR, DVAL_pca, LVAL)\n",
    "  binaryMVGModels(\"Tied MVG\", DTR_pca, LTR, DVAL_pca, LVAL, ML_func=Gau_Tied_ML_estimates)\n",
    "  binaryMVGModels(\"Naive Bayes MVG\", DTR_pca, LTR, DVAL_pca, LVAL, ML_func=Gau_Naive_ML_estimates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
